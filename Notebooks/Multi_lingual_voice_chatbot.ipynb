{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "luR4f_T9O-us"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JDSS-yzXO-u1"
      },
      "outputs": [],
      "source": [
        "llm_name = \"gpt-3.5-turbo-0301\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PPYkiXI1O-u3"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"../KnowledgeDocument(pan_card_services).txt\")\n",
        "corpus = loader.load()\n",
        "txt = ' '.join([d.page_content for d in corpus])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eJpfkIpEO-u4"
      },
      "outputs": [],
      "source": [
        "# Since the knowledge base is formatted like a markdown, using a markdown header splitter to get splits on headers and header information in metadata.\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "\n",
        "split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\"),\n",
        "]\n",
        "\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=split_on)\n",
        "md_header_splits = markdown_splitter.split_text(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OoT5g5FdO-u5"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "db = DocArrayInMemorySearch.from_documents(md_header_splits, embeddings)\n",
        "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "DeavkozeO-u6",
        "outputId": "4cb66b03-5762-4493-a636-aafaafd785d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PAN cards are not necessary for all individuals, but they are mandatory for NRIs with a source of income in India to file their taxes or if they want to invest in stocks or mutual funds in India. PAN cards are also required for financial transactions such as opening a bank account, investing in stocks, purchasing or selling property, and investing in India. Additionally, a PAN card is necessary to file income tax returns and invest in mutual funds in India.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Build prompt\n",
        "from langchain.prompts import PromptTemplate\n",
        "template = \"\"\"You are a helpful assistant, use the following context to answer the question at the end. If you don't know the answer, just say \"sorry, I can't answer this, the answer to this question does not appear in my knowledge base\", don't try to make up an answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template)\n",
        "\n",
        "# Run chain\n",
        "from langchain.chains import RetrievalQA\n",
        "question = \"Are PAN cards necessary?\"\n",
        "qa_chain = RetrievalQA.from_chain_type(llm,\n",
        "                                       retriever=db.as_retriever(),\n",
        "                                       return_source_documents=True,\n",
        "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
        "\n",
        "\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "zVvK5yaOO-u9",
        "outputId": "2c982441-9d96-4f7c-9dec-013696b0406a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-83f4d786fc46>:59: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
            "<ipython-input-27-83f4d786fc46>:59: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://7e82793b0e229a4eb0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7e82793b0e229a4eb0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import whisper\n",
        "import gradio as gr\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "model = whisper.load_model(\"small\")\n",
        "\n",
        "def transcribe(audio):\n",
        "\n",
        "    #time.sleep(3)\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "    lang = max(probs, key=probs.get)\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions(fp16 = False)\n",
        "    aud_to_text = whisper.decode(model, mel, options).text\n",
        "    if lang == \"en\":\n",
        "      translated_aud_to_text = aud_to_text\n",
        "      t_result = qa_chain({\"query\": translated_aud_to_text})[\"result\"]\n",
        "      return aud_to_text, \"No translation is needed as the language is English\", t_result, t_result, lang\n",
        "    else:\n",
        "      # translate from detected lang to en\n",
        "      prompt = PromptTemplate(\n",
        "      input_variables=[\"source\", \"target\", \"text\"],\n",
        "      template=\"Translate from language {source} to {target}: {text}?\",\n",
        "      )\n",
        "      chain = LLMChain(llm=llm, prompt=prompt)\n",
        "      translated_aud_to_text = chain.run({\n",
        "          'source': lang,\n",
        "          'target': \"en\",\n",
        "          'text': aud_to_text\n",
        "          })\n",
        "\n",
        "      t_result = qa_chain({\"query\": translated_aud_to_text})[\"result\"]\n",
        "      translated_answer = chain.run({\n",
        "          'source': \"en\",\n",
        "          'target': lang,\n",
        "          'text': t_result\n",
        "          })\n",
        "      return aud_to_text, translated_aud_to_text, translated_answer, t_result, lang\n",
        "\n",
        "aud_to_text = gr.Textbox(label=\"Transcribed Question\")\n",
        "translated_aud_to_text = gr.Textbox(label=\"Question translated to English\")\n",
        "translated_answer = gr.Textbox(label=\"Chatbot's answer in orginal langauge\")\n",
        "t_result = gr.Textbox(label=\"Chatbot's answer in English\")\n",
        "lang = gr.Textbox(label=\"Detected language\")\n",
        "\n",
        "gr.Interface(\n",
        "    title = 'Multi-lingual Voice based RAG chatbot',\n",
        "    fn=transcribe,\n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        aud_to_text, translated_aud_to_text, translated_answer, t_result, lang\n",
        "    ],\n",
        "    live=True).launch(share = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C7LYDD8kVo4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mlep-w1-lab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}